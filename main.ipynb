{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data....\n",
      "\n",
      "\n",
      "Show head data\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "\n",
      "Describe data\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "Nulls in training set\n",
      "\n",
      "\n",
      "\n",
      "['Age 177 nullos de 891', 'Cabin 687 nullos de 891', 'Embarked 2 nullos de 891']\n",
      "Nulls in submission set\n",
      "\n",
      "\n",
      "\n",
      "['Age 86 nullos de 418', 'Fare 1 nullos de 418', 'Cabin 327 nullos de 418']\n",
      "\n",
      "\n",
      "Setup and Data Loaded Complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "base_path = './'\n",
    "train_filepath = base_path + 'train.csv'\n",
    "test_filepath = base_path + 'test.csv'\n",
    "\n",
    "if os.path.exists(train_filepath):\n",
    "    print('Loading data....')\n",
    "    train_data = pd.read_csv(train_filepath)\n",
    "    test_data = pd.read_csv(test_filepath)\n",
    "    print(\"\\n\\nShow head data\")\n",
    "    print(train_data.head())\n",
    "    print(\"\\n\\nDescribe data\")\n",
    "    print(train_data.describe())\n",
    "    \n",
    "    print(\"Nulls in training set\")\n",
    "    cols_with_missing = ['{} {} nullos de {}'.format(col,train_data[col].isnull().sum(),train_data[col].isnull().count())\n",
    "                         for col in train_data.columns\n",
    "                         if train_data[col].isnull().any()]\n",
    "    print(\"\\n\\n\")\n",
    "    print(cols_with_missing)\n",
    "    \n",
    "    print(\"Nulls in submission set\")\n",
    "    cols_with_missing = ['{} {} nullos de {}'.format(col,test_data[col].isnull().sum(),test_data[col].isnull().count())\n",
    "                         for col in test_data.columns\n",
    "                         if test_data[col].isnull().any()]\n",
    "    print(\"\\n\\n\")\n",
    "    print(cols_with_missing)\n",
    "    \n",
    "    \n",
    "    print('\\n\\nSetup and Data Loaded Complete')\n",
    "else:\n",
    "    print('Files not exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Selection\n",
    "I delete cabin column because has many null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X data\n",
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0       3    male  22.0      1      0   7.2500        S\n",
      "1       1  female  38.0      1      0  71.2833        C\n",
      "2       3  female  26.0      0      0   7.9250        S\n",
      "3       1  female  35.0      1      0  53.1000        S\n",
      "4       3    male  35.0      0      0   8.0500        S\n",
      "5       3    male   NaN      0      0   8.4583        Q\n",
      "6       1    male  54.0      0      0  51.8625        S\n",
      "7       3    male   2.0      3      1  21.0750        S\n",
      "8       3  female  27.0      0      2  11.1333        S\n",
      "9       2  female  14.0      1      0  30.0708        C\n",
      "\n",
      "\n",
      "Y data\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    1\n",
      "9    1\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "Finished loaded...\n"
     ]
    }
   ],
   "source": [
    "X_data = train_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
    "y_data = train_data['Survived']\n",
    "X_send_data = test_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
    "X_passenger_id = test_data['PassengerId'].copy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size=1/5,random_state=0)\n",
    "\n",
    "print('\\nX data')\n",
    "print(X_data[:10])\n",
    "\n",
    "\n",
    "print('\\n\\nY data')\n",
    "print(y_data[:10])\n",
    "\n",
    "print('\\nFinished loaded...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Nomalization\n",
    " I fill age with average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imputer = imputer.fit(X_train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_norm = X_train.copy()\n",
    "X_test_norm = X_test.copy()\n",
    "X_send = X_send_data.copy()\n",
    "\n",
    "X_train_norm.loc[:,'Age'] = imputer.transform(X_train['Age'].values.reshape(-1, 1))\n",
    "X_test_norm.loc[:,'Age'] = imputer.transform(X_test['Age'].values.reshape(-1, 1))\n",
    "X_send.loc[:,'Age'] = imputer.transform(X_send['Age'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete 2 rows of embarked with null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~pd.isnull(X_train).any(axis=1)\n",
    "X_train_norm = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "mask = ~pd.isnull(X_test).any(axis=1)\n",
    "X_test_norm = X_test[mask]\n",
    "y_test = y_test[mask] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fill with the mean the Fare row in submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputerFare = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imputerFare = imputerFare.fit(X_train['Fare'].values.reshape(-1, 1))\n",
    "\n",
    "X_send.loc[:,'Fare'] = imputerFare.transform(X_send['Fare'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied one hot encoder to sex and embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass   Age  SibSp  Parch      Fare  is_female  is_C  is_Q\n",
      "439       2  31.0      0      0   10.5000        0.0   0.0   0.0\n",
      "817       2  31.0      1      1   37.0042        0.0   1.0   0.0\n",
      "378       3  20.0      0      0    4.0125        0.0   1.0   0.0\n",
      "491       3  21.0      0      0    7.2500        0.0   0.0   0.0\n",
      "331       1  45.5      0      0   28.5000        0.0   0.0   0.0\n",
      "..      ...   ...    ...    ...       ...        ...   ...   ...\n",
      "763       1  36.0      1      2  120.0000        1.0   0.0   0.0\n",
      "835       1  39.0      1      1   83.1583        1.0   1.0   0.0\n",
      "192       3  19.0      1      0    7.8542        1.0   0.0   0.0\n",
      "559       3  36.0      1      0   17.4000        1.0   0.0   0.0\n",
      "684       2  60.0      1      1   39.0000        0.0   0.0   0.0\n",
      "\n",
      "[569 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "object_cols = ['Sex','Embarked']\n",
    "columns = ['']\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train_norm[object_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test_norm[object_cols]))\n",
    "OH_cols_send = pd.DataFrame(OH_encoder.transform(X_send[object_cols]))\n",
    "\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train_norm.index\n",
    "OH_cols_test.index = X_test_norm.index\n",
    "OH_cols_send.index = X_send.index\n",
    "\n",
    "\n",
    "columns = []\n",
    "column = ''\n",
    "columns_to_drop = []\n",
    "for encoder in OH_encoder.categories_:\n",
    "    for column in encoder:\n",
    "        columns.append('is_{}'.format(column))\n",
    "    columns_to_drop.append('is_{}'.format(column))\n",
    "    \n",
    "OH_cols_train.columns = columns\n",
    "OH_cols_test.columns = columns\n",
    "OH_cols_send.columns = columns\n",
    "\n",
    "OH_cols_train = OH_cols_train.drop(columns_to_drop,axis=1)\n",
    "OH_cols_test =OH_cols_test.drop(columns_to_drop,axis=1)\n",
    "OH_cols_send =OH_cols_send.drop(columns_to_drop,axis=1)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train_norm = X_train_norm.drop(object_cols, axis=1)\n",
    "num_X_test_norm = X_test_norm.drop(object_cols, axis=1)\n",
    "num_X_send = X_send.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train_norm, OH_cols_train], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test_norm, OH_cols_test], axis=1)\n",
    "OH_X_send = pd.concat([num_X_send, OH_cols_send], axis=1)\n",
    "\n",
    "print(OH_X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.29244176  0.09104097 -0.54710127 -0.50182111 -0.43987676 -0.73054276\n",
      "  -0.45895348 -0.20524264]\n",
      " [-0.29244176  0.09104097  0.55290093  0.65419594  0.05799956 -0.73054276\n",
      "   2.17887006 -0.20524264]\n",
      " [ 0.90467594 -0.66419484 -0.54710127 -0.50182111 -0.56174321 -0.73054276\n",
      "   2.17887006 -0.20524264]\n",
      " [ 0.90467594 -0.59553704 -0.54710127 -0.50182111 -0.50092739 -0.73054276\n",
      "  -0.45895348 -0.20524264]\n",
      " [-1.48955945  1.08657907 -0.54710127 -0.50182111 -0.10175021 -0.73054276\n",
      "  -0.45895348 -0.20524264]\n",
      " [ 0.90467594 -0.52687924 -0.54710127 -0.50182111 -0.48589954 -0.73054276\n",
      "  -0.45895348 -0.20524264]\n",
      " [ 0.90467594 -0.25224803 -0.54710127 -0.50182111 -0.49106536 -0.73054276\n",
      "  -0.45895348 -0.20524264]\n",
      " [-0.29244176 -0.32090584  0.55290093  0.65419594 -0.073573    1.36884527\n",
      "  -0.45895348 -0.20524264]\n",
      " [ 0.90467594 -0.59553704  0.55290093 -0.50182111 -0.45255651  1.36884527\n",
      "  -0.45895348 -0.20524264]\n",
      " [-1.48955945  0.09104097  0.55290093 -0.50182111  0.33969279 -0.73054276\n",
      "  -0.45895348 -0.20524264]]\n",
      "Finished preprocessing\n"
     ]
    }
   ],
   "source": [
    "#Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "X_trainf = sc_X.fit_transform(OH_X_train)\n",
    "X_testf = sc_X.transform(OH_X_test)\n",
    "X_sendf = sc_X.transform(OH_X_send)\n",
    "\n",
    "\n",
    "print(X_trainf[:10])\n",
    "\n",
    "print('Finished preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC\n",
    "Selecting best model Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy 78.96666666666667%\n",
      "Best pameters \n",
      " {'C': 5.5, 'dual': False, 'max_iter': 213, 'penalty': 'l1', 'tol': 0.0007000000000000001}\n"
     ]
    }
   ],
   "source": [
    "#Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "    {'penalty':['l1'],'dual':[False],'C':[5.5],'max_iter':[213],'tol':np.arange(0.0001, 0.001, 0.0001).tolist()}\n",
    "]\n",
    "grid_search = GridSearchCV(estimator=LinearSVC(),\n",
    "                         param_grid=parameters,\n",
    "                         scoring='accuracy',\n",
    "                         cv=100,\n",
    "                         n_jobs=-1)\n",
    "grid_search = grid_search.fit(X_trainf,y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Best accuracy {}%\".format(best_accuracy*100))\n",
    "print(\"Best pameters \\n {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model Linear SVC\n",
    "\n",
    "Position 9846\n",
    "\n",
    "Score 0.77511\n",
    "\n",
    "Precision 78.96%\n",
    "\n",
    "Variance 15.81%\n",
    "\n",
    "TRAIN\n",
    "\n",
    "True positives 292 -\n",
    "False positives 48 -\n",
    "False negative 69 -\n",
    "True negative 160 -\n",
    "\n",
    "\n",
    "TEST\n",
    "\n",
    "True positives 69 -\n",
    "False positives 15 -\n",
    "False negative 13 -\n",
    "True negative 46 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=5.5, dual=False, max_iter=213, penalty='l1', tol=0.0007)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "best_model = LinearSVC(max_iter=213,dual=False, tol=0.0007, C=5.5,penalty='l1')\n",
    "best_model.fit(X_trainf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "True positives 292 \n",
      "False positives 48 \n",
      "False negative 69 \n",
      "True negative 160\n",
      "\n",
      "\n",
      "TEST\n",
      "True positives 69 \n",
      "False positives 15 \n",
      "False negative 13 \n",
      "True negative 46\n",
      "\n",
      "\n",
      "Precision 78.96666666666667%\n",
      "Variance 15.816271508938017%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_predict = clf.predict(OH_X_train)\n",
    "cm = confusion_matrix(y_train,y_predict)\n",
    "print(\"TRAIN\\nTrue positives {} \\nFalse positives {} \\nFalse negative {} \\nTrue negative {}\\n\\n\".format(cm[0][0],cm[0][1],cm[1][0],cm[1][1]))\n",
    "\n",
    "y_predict_test = clf.predict(OH_X_test)\n",
    "cm = confusion_matrix(y_test,y_predict_test)\n",
    "print(\"TEST\\nTrue positives {} \\nFalse positives {} \\nFalse negative {} \\nTrue negative {}\\n\\n\".format(cm[0][0],cm[0][1],cm[1][0],cm[1][1]))\n",
    "\n",
    "\n",
    "#Applying k-Flod Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=clf, X=OH_X_train, y=y_train, cv=100)\n",
    "\n",
    "\n",
    "print(\"Precision {}%\".format(accuracies.mean()*100))\n",
    "#Indica la varianza\n",
    "print(\"Variance {}%\".format(accuracies.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_testf,y_test)\n",
    "y_send = best_model.predict(X_sendf)\n",
    "\n",
    "data = {'PassengerId': X_passenger_id,\n",
    "        'Survived': y_send}\n",
    "\n",
    "df = pd.DataFrame (data)\n",
    "df.to_csv('submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
