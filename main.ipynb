{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data....\n",
      "\n",
      "\n",
      "Show head data\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "\n",
      "Describe data\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "\n",
      "\n",
      "['Age 177 nullos de 891', 'Cabin 687 nullos de 891', 'Embarked 2 nullos de 891']\n",
      "\n",
      "\n",
      "Setup and Data Loaded Complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "base_path = './'\n",
    "train_filepath = base_path + 'train.csv'\n",
    "test_filepath = base_path + 'test.csv'\n",
    "\n",
    "if os.path.exists(train_filepath):\n",
    "    print('Loading data....')\n",
    "    train_data = pd.read_csv(train_filepath)\n",
    "    test_data = pd.read_csv(test_filepath)\n",
    "    print(\"\\n\\nShow head data\")\n",
    "    print(train_data.head())\n",
    "    print(\"\\n\\nDescribe data\")\n",
    "    print(train_data.describe())\n",
    "    \n",
    "    cols_with_missing = ['{} {} nullos de {}'.format(col,train_data[col].isnull().sum(),train_data[col].isnull().count())\n",
    "                         for col in train_data.columns\n",
    "                         if train_data[col].isnull().any()]\n",
    "    print(\"\\n\\n\")\n",
    "    print(cols_with_missing)\n",
    "    \n",
    "    print('\\n\\nSetup and Data Loaded Complete')\n",
    "else:\n",
    "    print('Files not exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Selection\n",
    "I delete cabin column because has many null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X data\n",
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0       3    male  22.0      1      0   7.2500        S\n",
      "1       1  female  38.0      1      0  71.2833        C\n",
      "2       3  female  26.0      0      0   7.9250        S\n",
      "3       1  female  35.0      1      0  53.1000        S\n",
      "4       3    male  35.0      0      0   8.0500        S\n",
      "5       3    male   NaN      0      0   8.4583        Q\n",
      "6       1    male  54.0      0      0  51.8625        S\n",
      "7       3    male   2.0      3      1  21.0750        S\n",
      "8       3  female  27.0      0      2  11.1333        S\n",
      "9       2  female  14.0      1      0  30.0708        C\n",
      "\n",
      "\n",
      "Y data\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    1\n",
      "9    1\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "Finished loaded...\n"
     ]
    }
   ],
   "source": [
    "X_data = train_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
    "y_data = train_data['Survived']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size=1/4,random_state=0)\n",
    "\n",
    "print('\\nX data')\n",
    "print(X_data[:10])\n",
    "\n",
    "\n",
    "print('\\n\\nY data')\n",
    "print(y_data[:10])\n",
    "\n",
    "print('\\nFinished loaded...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Nomalization\n",
    " I fill age with average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imputer = imputer.fit(X_train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_norm = X_train.copy()\n",
    "X_test_norm = X_test.copy()\n",
    "\n",
    "X_train_norm.loc[:,'Age'] = imputer.transform(X_train['Age'].values.reshape(-1, 1))\n",
    "X_test_norm.loc[:,'Age'] = imputer.transform(X_test['Age'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete 2 rows of embarked with null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~pd.isnull(X_train).any(axis=1)\n",
    "X_train_norm = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "mask = ~pd.isnull(X_test).any(axis=1)\n",
    "X_test_norm = X_test[mask]\n",
    "y_test = y_test[mask] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied one hot encoder to sex and embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass   Age  SibSp  Parch     Fare  is_female  is_C  is_Q\n",
      "105       3  28.0      0      0   7.8958        0.0   0.0   0.0\n",
      "68        3  17.0      4      2   7.9250        1.0   0.0   0.0\n",
      "253       3  30.0      1      0  16.1000        0.0   0.0   0.0\n",
      "320       3  22.0      0      0   7.2500        0.0   0.0   0.0\n",
      "706       2  45.0      0      0  13.5000        1.0   0.0   0.0\n",
      "..      ...   ...    ...    ...      ...        ...   ...   ...\n",
      "835       1  39.0      1      1  83.1583        1.0   1.0   0.0\n",
      "192       3  19.0      1      0   7.8542        1.0   0.0   0.0\n",
      "629       3  29.9      0      0   7.7333        0.0   0.0   1.0\n",
      "559       3  36.0      1      0  17.4000        1.0   0.0   0.0\n",
      "684       2  60.0      1      1  39.0000        0.0   0.0   0.0\n",
      "\n",
      "[666 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "object_cols = ['Sex','Embarked']\n",
    "columns = ['']\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train_norm[object_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test_norm[object_cols]))\n",
    "\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train_norm.index\n",
    "OH_cols_test.index = X_test_norm.index\n",
    "\n",
    "columns = []\n",
    "column = ''\n",
    "columns_to_drop = []\n",
    "for encoder in OH_encoder.categories_:\n",
    "    for column in encoder:\n",
    "        columns.append('is_{}'.format(column))\n",
    "    columns_to_drop.append('is_{}'.format(column))\n",
    "    \n",
    "OH_cols_train.columns = columns\n",
    "OH_cols_test.columns = columns\n",
    "\n",
    "OH_cols_train = OH_cols_train.drop(columns_to_drop,axis=1)\n",
    "OH_cols_test =OH_cols_test.drop(columns_to_drop,axis=1)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train_norm = X_train_norm.drop(object_cols, axis=1)\n",
    "num_X_test_norm = X_test_norm.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train_norm, OH_cols_train], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test_norm, OH_cols_test], axis=1)\n",
    "\n",
    "print(OH_X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('linearsvc',\n",
       "                 LinearSVC(dual=False, max_iter=10000, random_state=0,\n",
       "                           tol=1e-05))])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                     LinearSVC(random_state=0,max_iter=10000,dual=False, tol=1e-5))\n",
    "clf.fit(OH_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116  23]\n",
      " [ 24  60]]\n",
      "0.7958842152872003\n",
      "0.030346067981925667\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf.predict(OH_X_train)\n",
    "y_predict_test = clf.predict(OH_X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_predict_test)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "#Applying k-Flod Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=clf, X=OH_X_train, y=y_train, cv=10)\n",
    "\n",
    "print(accuracies.mean())\n",
    "#Indica la varianza\n",
    "print(accuracies.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "validation_curve() missing 2 required keyword-only arguments: 'param_name' and 'param_range'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-72605b315c45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidation_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Gráfico error entrenamiento vs error testeo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: validation_curve() missing 2 required keyword-only arguments: 'param_name' and 'param_range'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "train_scores,test_scores = validation_curve(LinearSVC(random_state=0,max_iter=10000,dual=False, tol=1e-5),X_train,y_train,cv=5)\n",
    "np.mean(train_scores,axis=1)\n",
    "#Gráfico error entrenamiento vs error testeo\n",
    "plt.plot(np.mean(train_scores,axis=1))\n",
    "plt.plot(np.mean(test_scores,axis=1))\n",
    "plt.xticks(np.arange(24),n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
